{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fahrmodell optimieren\n",
    "\n",
    "‚ö†Ô∏è **In diesem Notebook befinden sich Aufgaben. Ihr m√ºsst die gel√∂sten Aufgaben eurem Coach abgeben, damit sie bewertet werden.** ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir unser erstes Modell trainiert haben, ist es wahrscheinlich noch nicht perfekt. Machine learning lebt davon ein Modell St√ºck um St√ºck zu verbessern. Jetzt geht es darum, das Modell Schritt f√ºr Schritt zu verbessern. Ein Methodisches vorgehen lohnt sich:\n",
    "1. Eine √Ñnderung am Modell oder den Daten machen und das Modell trainieren\n",
    "2. Genau dokumentieren und die Hyperparameter, Architektur, Datenset, ... im Run Ordner speichern.\n",
    "3. Das Modell auswerten und auch diese Informationen (Loss, Trainingsverlauf, ...) im Run Ordner speichern.\n",
    "4. Die Resultate vergleichen und entscheiden ob die √Ñnderung beibehalten wird oder nicht.\n",
    "    - Falls das Modell schlechter wurde, √ºberlegen wieso und ob wir etwas dagegen tun k√∂nnen.\n",
    "5. Immer wieder auf einer Teststrecke mit dem Auto Testen.\n",
    "\n",
    "Es gibt verschiedene M√∂glichkeiten das Fahrmodell zu verbessern:\n",
    "\n",
    "### Augmentation\n",
    "- Informier dich in der Dokumentation was die Parameter von `ColorJitter` bewirken und spiele damit herum. Kannst du so dein Modell verbessern?\n",
    "- F√ºge weitere Transformationen ein, welche f√ºr unseren Anwendungsfall sinnvoll sind, und schaue, ob dein Model dadurch besser wird. Z.B:\n",
    "  - Leichte Drehung (nur wenige Grad)\n",
    "  - Blur (Unsch√§rfe)\n",
    "  - Resize/Crop (auch hier nur um wenige Pixel)\n",
    "- Um zu sehen, ob das Modell besser ist, kannst du auf den Fehler im Trainings-Set schauen. Zus√§tzlich kannst du schauen, ob das Auto auf einer noch nie gesehen Bahn besser ist und mit den Lichtverh√§ltnissen im Raum spielen (andere Tageszeit, L√§den √∂ffnen/schliessen, verschiedenen Lampen etc.)\n",
    "\n",
    "### Hyperparameter\n",
    "Teste verschiedene Werte f√ºr die Hyperparameter (Lernrate, Anzahl Epochen, Batch-Size usw.)\n",
    "\n",
    "### Daten\n",
    "Die Anzahl und Auswahl der Daten hat einen grosssen Einfluss auf dein Modell. Oft lohnt es sich mehr Daten zu sammeln aber die Auswahl (Verschiedene Daten) und Qualit√§t ist ebenso wichtig.\n",
    "\n",
    "### Architektur (Anspruchsvoll)\n",
    "Die vorgegebene Architektur sollte bereits gut funktionieren. Aber nat√ºrlich kannst du auch an der Architektur des Modells herumexperimentieren:\n",
    "- Anzahl Convolution Layers (Feature Extractor)\n",
    "- Anzahl Linear Layers (Classifier)\n",
    "- Anzahl Channels in den Layers\n",
    "- Stride Gr√∂sse in den Layers\n",
    "\n",
    "Findest du eine Architektur, welche noch besser funktioniert?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Aufgabe 3.7\n",
    "\n",
    "Trainiere min. verschiedene 4 Modelle und f√ºhre Buch √ºber deine Experimente. Zum Beispiel in einer Tabelle wie dieser:\n",
    "\n",
    "| Datum    | Experiment Name | Notizen / √Ñnderung | Trainingsdaten (Welche, Anzahl) | Anzahl Epochen | Architektur | Error Validierungs-Set | Fahrtest bestanden? | Error Test-Set (Zusatzaufgabe) |\n",
    "|----------|----------------|--------------------|--------------------------------|----------------|-------------|-----------------------|---------------------|-------------------------------------|\n",
    "| 08.11.25 | Fahrmodell_v1  | lr = 0.001         | 10k, Ordner: data/drive-1      | 30             | Standart    | 5.6                   | Ja                  | 7.2                                 |\n",
    "|          |                |                    |                                |                |             |                       |                     |                                     |\n",
    "|          |                |                    |                                |                |             |                       |                     |                                     |\n",
    "|          |                |                    |                                |                |             |                       |                     |                                     |\n",
    "|          |                |                    |                                |                |             |                       |                     |                                     |\n",
    "|          |                |                    |                                |                |             |                       |                     |                                     |\n",
    "\n",
    "Pr√§sentiere deine Resultate deinem Betreuer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusatzaufgabe (freiwillig)\n",
    "\n",
    "Wie in der Theorie erw√§hnt, gibt es neben Train- und Validierungs-Set oft auch noch ein Testset. Das Testset ist ein komplett eigenst√§ndiges Set von Daten, welches nur f√ºr die √úberpr√ºfung verwendet wird. Daten aus dem Testset werden nie f√ºrs Training verwendet (auch nicht Teile davon). So erh√§ltst du schnell ein Feedback, wie dein Model auf eine noch nie gesehen Bahn reagiert.\n",
    "\n",
    "- Nimm eine Runde auf einer Bahn auf, welche du nur f√ºr diesen Test verwendest und nie f√ºrs Training. Das ist unser Testset.\n",
    "- Du kannst entweder ein neues Notebook erstellen und das exportierte ONNX Modell laden (benutze den Code aus `predict.py` (schwieriger) oder du verwendest das Trainierte Modell aus dem Trainings-Notebook und testest das Modell gleich nach dem Training (einfacher).\n",
    "- F√ºge im Notebook (Neu oder Training) einige Zellen hinzu welches das Testset mit deinem Modell vorhersagt und dir den durchschnittlichen Fehler berechnet:\n",
    "    - Bilder als Datenset einlesen\n",
    "    - Das trainierte Modell mit `calculate_error` und `visualize_angels` testen\n",
    "    - Die Resultate vergleichen oder im Run Ordner speichern\n",
    "\n",
    "Verwende anschliessend vor allem die Resultate aus dem Testset um dein Training zu beurteilen, nicht mehr das Validierungsset. Mit einem unabh√§ngigen Testset kannst du viel aussagekr√§ftigere Aussagen zu deinem Modell machen, gezielter optimieren und bist besser f√ºr die Challenges vorbereitet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
