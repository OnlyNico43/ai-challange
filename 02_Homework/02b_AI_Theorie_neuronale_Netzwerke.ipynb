{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Künstliche Intelligenz und neuronale Netzwerke\n",
    "\n",
    "## Begriffe rund um AI\n",
    "\n",
    "Wir werden uns als Einstieg einige Begriffe anschauen.\n",
    "\n",
    "- **KI/AI:** Steht für Künstliche Intelligenz (englisch: Artificial Intelligence). Es ist sozusagen der oberste Begriff und beschreibt genau das, was es sagt: Eine Maschine, welche die natürliche \"Intelligenz\" wie Lebewesen sie haben, nachzuahmen versucht. AI ist ein allgemeines Konzept und spezifiziert nicht genauer, was die Maschine macht.\n",
    "\n",
    "- **Maschinelles Lernen:** ML (englisch: Machine Learning) ist eine Möglichkeit von AI. Dabei extrahieren Maschinen Informationen aus Daten, um aus diesen autonom lernen zu können. In Fachkreisen wird lieber von ML gesprochen als von AI, da es genauer beschreibt, um was es geht.\n",
    "\n",
    "- **Künstliche neuronale Netzwerke (KNN) / Deep Learning**: Eine Möglichkeit ML zu betreiben ist, neuronale Netzwerke [englisch: Artificial Neural Networks (ANN)] einzusetzen. Schaltet man sehr viele solcher Schichten solcher Netze hintereinander, so spricht man von Deep Learning. Deep Learning wurde erst möglich, als Computerhardware leistungsstark genug dafür wurde. Neben neuronalen Netzen gibt es noch andere Methoden, um ML zu betreiben, zum Beispiel lineare Regression oder Entscheidungsbäume. Bei der AI-Challenge wird es aber hauptsächlich um neuronale Netzwerke gehen.\n",
    "\n",
    "Diese Grafik verdeutlicht die Zusammenhänge der Begriffe:\n",
    "\n",
    "![AI_Techniques_Overview](../assets/02_AI_overview.png)  \n",
    "<small>Quelle https://commons.wikimedia.org/wiki/File:AI_Techniques_Overview.png (CC)</small>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netzwerke\n",
    "\n",
    "Wie funktioniert nun so ein neuronales Netzwerk und woraus besteht es?\n",
    "\n",
    "Die Videos der letzten Woche haben schon eine ziemlich gute Einführung erhalten. Falls ihr diese noch nicht geschaut habt, unbedingt nachholen!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ein künstliches Neuron\n",
    "\n",
    "Ein neuronales Netzwerk setzt sich aus vielen einzelnen künstlichen Neuronen zusammen. Der Begriff Neuron lehnt sich dabei an, wie die Neuronen im Gehirn funktionieren (auch wenn dies einiges komplizierter ist und immer noch nicht komplett erforscht ist).\n",
    "\n",
    "Künstliche Neuronen sind im Aufbau eigentlich recht simpel. Im Grunde besteht jedes Neuron aus mehreren **Eingängen** und einem **Ausgang**. Durch jeden Eingang erhält das Neuron einen Wert. Alle diese Eingangswerte werden addiert und danach noch ein fixer Wert, den sogenannten **Bias**, dazugerechnet. Mathematisch gesehen ist das also:\n",
    "\n",
    "$(Eingang_{1} + Eingang_{2} + ... + Eingang_{n}) + Bias  = Ausgang$\n",
    "\n",
    "oder das Gleiche mit der Summenformel, falls du diese kennst:\n",
    "\n",
    "$\\sum_{i=1}^{n} Eingang_{i} + b$\n",
    "\n",
    "Da die Eingangswerte alle gegeben sind ist der einzige Wert den das Neuron kontrollieren kann der Bias. Das reicht uns noch nicht um wirklich zu lernen. Dazu benötigen wir mehr Werte welche wir verändern können. Dazu geben wir jedem Eingangswert ein Gewicht (Weight). Mit diesen Weights können wir steuern wie stark ein Eingangsignal im Output ist:\n",
    "\n",
    "$(Eingang_{1} * Gewicht_{1} + Eingang_{2} * Gewicht_{2} + Eingang_{n} * Gewicht_{n}) + Bias  = Ausgang$\n",
    "\n",
    "oder mit der Summenformel:\n",
    "\n",
    "$\\sum_{i=1}^{n} Eingang_{i} * Gewicht_{i} + Bias * Gewicht_{b}$\n",
    "\n",
    "Diese Werte der **Gewichte** und **Bias** wird das neuronale Netzwerk im Laufe des Trainings lernen.\n",
    "\n",
    "Zuletzt folgt noch eine **Aktivierungsfunktion**. Diese kann unterschiedlich aussehen, sorgt jedoch dafür, dass das Netzwerk noch nicht-lineare Funktionen und somit komplexere Zusammenhänge lernen kann. So werden z.B. schwache (und deshalb nicht relevante) Signale unterdrückt, welche sonst das Netzwerk stören würden. Auch dieses Vorgehen ist aus der Natur entlehnt, bei Muskeln etwa werden schwache Signale der Nerven unterdrückt, da wir sonst immer leicht zittern würden (siehe [Schwellenpotential](https://de.wikipedia.org/wiki/Schwellenpotential)). Die am häufigsten verwendete Aktivierungsfunktion heisst [**ReLU**](https://de.wikipedia.org/wiki/Rectifier_(neuronale_Netzwerke)).  \n",
    "\n",
    "Als Grafik dargestellt, sieht das Ganze so aus:\n",
    "\n",
    "![ArtificialNeuronModel_deutsch](../assets/ArtificialNeuronModel_deutsch.png)\n",
    "<small>Quelle https://de.wikipedia.org/wiki/K%C3%BCnstliches_Neuron#/media/Datei:ArtificialNeuronModel_deutsch.png (CC)</small>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Schichten unseres Netzwerks\n",
    "\n",
    "Verbinden wir nun ganz viele dieser künstlichen Neuronen miteinander, so entsteht ein neuronales Netz. Fast immer sind dabei mehrere **Schichten (Layer)** aus Neuronen  hintereinander angeordnet. Das bedeutet, von der **Eingabeschicht**, welche das gesamte Eingangssignal (z.B. ein Bild) erhält, führen alle Neuronen ihr Ausgangssignal wiederum zu jedem Neuron der nächsten Schicht. Die mittleren Schichten werden **Hidden Layers** genannt. Es kann mehrere solcher Hidden Layers geben. Gibt es sehr viele, spricht man von einem **Deep Neuronal Network (DNN)**. Als letztes folgt die **Ausgabeschicht**, sie gibt das Resultat aus.\n",
    "\n",
    "![Neuronal_Network_scheme](https://upload.wikimedia.org/wikipedia/commons/9/95/Neuronal_Network_scheme.JPG)  \n",
    "<small>Quelle https://commons.wikimedia.org/wiki/File:Neuronal_Network_scheme.JPG (CC)</small>\n",
    "\n",
    "Die Anzahl Neuronen pro Schicht werden dabei in der Regel immer weniger. Dadurch werden die Informationen immer weiter reduziert und nur die für das Ziel relevanten Signale kommen durch. Die Ausgabeschicht hat dann nur noch die Anzahl Neuronen, wie unser Ausgangssignal aussehen soll. Zum Beispiel hat eine Bilderkennung, welche Katzen erkennen soll, als Ausgang nur noch ein Neuronen. Ein Netzwerk, dass Ziffern erkennt, hätte hingegen 10 Ausgangs-Neuronen, nämlich eines Pro Ziffer (0..9).\n",
    "\n",
    "**Beispiel:** Ein Netzwerk soll Katzen auf Bildern mit Grösse 180x180 identifiziert\n",
    "\n",
    "- **Eingangs-Schicht:** Es benötigt für jedes Pixel und jeden Farbkanal (Rot/Grün/Blau) ein Neuron, also 3\\*180px\\*180px=97'200 Eingänge\n",
    "- **Hidden Layers**: Zum Beispiel drei Layers mit 16'000 Neuronen, 4'000 Neuronen und 1'000 Neuronen\n",
    "- **Ausgangsschicht:** Ein Neuronen, dessen Wert das Resultat angibt. In diesem Fall die Wahrscheinlichkeit, ob es eine Katze ist oder nicht\n",
    "\n",
    "Eine solche Kombination von Schichten, sowie die dazugehörigen Parameter, wird auch als **Model-Architektur** oder einfach nur **Modell** bezeichnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Loss-Function (Fehlerfunktion)\n",
    "\n",
    "Während dem Training wollen wir wissen wie gut die Vorhersage unseres Modells ist. Dazu verwenden wir eine Loss-Function. Sie berechnet den Fehler zwischen der Vorhersage und dem echten Wert. Als den Fehler, den das neuronale Netz macht.\n",
    "\n",
    "Je nach dem, was unsere Absicht ist, ist diese Funktion anders:\n",
    "\n",
    "#### Regression:\n",
    "\n",
    "Haben wir ein Regressions-Problem zu lösen, also einen Wert möglichst genau vorherzusagen, so verwenden wir meisten die [Mittlere Quadratische Abweichung](https://de.wikipedia.org/wiki/Mittlere_quadratische_Abweichung) (englisch Mean Squared Error oder kurz MSE). Die Formel dafür sieht so aus:\n",
    "\n",
    "$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - y_{pred,i})^2 $\n",
    "\n",
    "Sieht kompliziert aus? Ist es aber gar nicht! Alles was wir machen ist:\n",
    "\n",
    "1. Die Differenz zwischen echten Wert ($y$) und Vorhersage ($y_{pred}$) zu berechnen\n",
    "2. Die Differenz zu quadrieren\n",
    "3. Den Durchschnitt berechnen\n",
    "\n",
    "Also zum Beispiel: vorhergesagt Werte `y_pred =[ 1.2, 5.2 ]`, echte Werte `y = [ 1.5, 4.9 ]`\n",
    "1. Differenzen berechnen: `error = [ 1.2-1.5, 5.2-4.7 ] = [ -0.3, 0.5 ]`\n",
    "2. Differenzen quadrieren: `quad_error = [ -0.3^2, 0.5^2 ] = [ 0.09, 0.25 ]`\n",
    "3. Den Durchschnitt berechnen: `mse = (0.09 + 0.25) / 2 = 0.17`\n",
    "\n",
    "Einfach, oder? In PyTorch macht das für uns die Funktion `loss = torch.nn.functional.mse_loss(y_pred, y)`\n",
    "\n",
    "#### Klassifikation:\n",
    "\n",
    "Bei der Klassifikation, also Vorhersage von Klassen (z.B. Katze / Keine Katze) benützen wir hingegen die [Kreuzentropie](https://de.wikipedia.org/wiki/Kreuzentropie) (englisch Cross Entropy). Diese ist ein bisschen kompliziert, berechnet aber einfach gesagt den Fehler bei der Vorhersage von Wahrscheinlichkeiten. Sie wird deshalb auch oft [Likelihood-Funktion](https://de.wikipedia.org/wiki/Likelihood-Funktion) genannt.\n",
    "\n",
    "In PyTorch macht das für uns die Funktion `loss = torch.nn.functional.cross_entropy(y_pred, y)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Training\n",
    "\n",
    "Was bedeutet es nun, wenn wir sagen *\"eine KI lernt\"* oder *\"wir trainieren ein neuronales Netz\"*? Das bedeutet, dass ein spezieller Algorithmus (der **Optimizer**) so lange die Gewichte der Neuronen anpasst (bildlich gesprochen: \"an den Gewichten herumschraubt\"), bis das Ausgangssignal das gewünschte Resultat liefert, respektive der Fehler (englisch: **Loss**), den das Netzwerk macht, geringer wird.\n",
    "\n",
    "Macht das Netzwerk dies wiederholt und für ganz viele unterschiedliche Eingangssignale, so wird es irgendwann einen Zustand erreichen, wo der Fehler genügend niedrig ist und das Ausgangssignal in den meisten Fällen korrekt ist. Das Netzwerk ist nun also trainiert und hat gelernt, eine bestimmte Aufgabe bestmöglich zu erfüllen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Der Machine-Learning-Ablauf\n",
    "\n",
    "Was brauchen wir alles für ein erfolgreiches Training?\n",
    "\n",
    "Der Ablauf beim maschinellen Lernen lässt sich als eine Art Kochrezept vorstellen. Es beschreibt die Schritte und Zutaten, welche nötig sind um am Schluss \"etwas Gutes\", also ein gutes Modell zu erhalten:\n",
    "\n",
    "1. **Daten sammeln**  \n",
    "   Für ML benötigen wir erstmal ganz viele Daten, anhand welcher unser Modell trainieren kann. Bei uns entspricht das den Kamera-Aufnahmen unseres Autos, welche wir aufnehmen müssen.\n",
    "2. **Daten aufbereiten**  \n",
    "   Die Daten müssen anschliessend aufbereitet werden. Das beinhaltet verschiedene Schritte, wie zum Beispiel das Bereinigen, also löschen von unnützen oder doppelten Daten. Oder auch eine Bilddatei in ein Format bringen, welches als Eingangssignal für ein neuronales Netzwerk taugt.\n",
    "3. **Modell definieren & trainieren**  \n",
    "   Wir müssen festlegen, wie unser neuronales Netzwerk aufgebaut ist, Parameter (z.B. Learning Rate) festlegen und es schlussendlich trainieren.\n",
    "4. **Modell validieren**  \n",
    "   Bei der Validierung geht es darum, abzuschätzen, wie gut unser Netzwerk seine Aufgabe erfüllt. Das machen wir mit anderen Daten als diese, welche wir fürs Training verwendet haben. Nur so können wir überprüfen, wie gut das Netzwerk in der Praxis wirklich ist.\n",
    "5. **Modell optimieren**  \n",
    "   Mit den Ergebnissen aus Training und Validierung können wir versuchen, unser Netzwerk noch besser zu machen. Dabei gibt es viele Möglichkeiten, inklusive mehr oder andere Trainingsdaten zu sammeln, oder einfach nur einen Parameter anzupassen. Wir gehen also, je nachdem, auf Schritt 1., 2. oder 3. zurück und wiederholen so lange, bis wir zufrieden mit dem Modell sind.\n",
    "6. **Modell anwenden**  \n",
    "   Im letzten Schritt wenden wir unser Modell in der Praxis an. Bei uns entspricht das den Challenges in der Mitte und am Schluss der AI-Challenge. Im echten Leben sammelt man meistens weiter Daten und Erkenntnisse, mit denen man sein Modell immer weiter verbessern kann. Also ein ewiger Kreislauf.\n",
    "\n",
    "![](../assets/Diagramm_ml_cycle.png)\n",
    "\n",
    "Wir werden uns jetzt einige wichtige Begriffe und Techniken rund ums Training sowie der Validierung anschauen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten, Daten, viele Daten... (Trainings- und Validierungsset)\n",
    "\n",
    "Wie schon erwähnt, brauchen wir fürs Training erstmals viele Daten. Vor dem Training werden diese Daten in verschiedene Sets aufgeteilt:\n",
    "\n",
    "- **Trainings-Set:** Ein Teil der Daten (meistens etwa 80%) werden fürs Training verwendet. Das Modell lernt an diesen Daten gute Vorhersagen zu machen.\n",
    "\n",
    "- **Validation-Set:** Der Rest der Daten wird für die Validierung (Überprüfung) verwendet. Wir benützten diese Daten also nicht zum Lernen, sondern zur Überprüfung wie gut unser Modell ist. Das heisst, wie gut es seine Aufgabe mit Daten erfüllt, welche es beim Training noch nicht gesehen hat. So können wir die Qualität unseres Modelles abschätzen und wenn nötig Anpassungen vornehmen.\n",
    "\n",
    "- **Test-Set:** Manchmal gibt es noch ein Test-Set. Dieses wird ganz am Anfang weggenommen und erst ganz am Schluss für die finale Validierung verwendet. So wird sichergestellt, dass das Modell diese Daten garantiert nie gesehen hat. Bei AI-Challenges (nicht nur bei unserer), bleibt dieses Set bis zum Schluss geheim. Erst beim Wettbewerb zeigt sich, wie gut die verschiedenen Modelle mit diesen völlig unbekannten Daten funktionieren.\n",
    "\n",
    "![ML_dataset_training_validation_test_sets](../assets/02_dataset.png)  \n",
    "<small>Quelle https://commons.wikimedia.org/wiki/File:ML_dataset_training_validation_test_sets.png (CC)</small>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zuviel des Guten (Under- und Overfitting)\n",
    "\n",
    "Beim Lernen ist es nötig, eine gute Balance zwischen **Underfitting** und **Overfitting** zu finden. Diese zwei wichtigen Begriffe wollen wir kurz erklären:\n",
    "\n",
    "- **Underfitting:** Das Modell hat schlecht gelernt oder zu wenig trainiert und kann seine Aufgabe ungenügend erfüllen (zu ungenau, zu grosse Fehler)\n",
    "\n",
    "- **Overfitting:** Das Modell hat zu viel trainiert und dabei die Trainingsdaten \"auswendig\" gelernt. Das heisst zum Beispiel, es hat nicht gelernt, etwas auf einem Bild zu erkennen, sondern einfach \"wenn exakt dieses Bild kommt, sage ich A oder B\". Dabei ist es ist bei den Trainingsdaten sehr genau. Mit Daten, die es noch nie gesehen hat (z.B. Validierungsdaten), macht es jedoch viele Fehler.\n",
    "\n",
    "Am besten machen wir dazu ein Beispiel: Die Aufgabe ist es, durch das Alter einer Person, seine Anzahl Stunden für Freizeitaktivitäten vorherzusagen. Dazu hat man einige Personen befragt und Daten gesammelt. Natürlich ist es bei jedem Menschen und seiner Lebenssituation anders, aber generell wird man in der Jugend viel Freizeit haben, dann kommt Arbeit und Familie mit weniger Freizeit und im Alter hat man dann wieder mehr zur Verfügung.\n",
    "\n",
    "Die Aufgabe des Modells ist es nun, eine möglichst allgemein gültige Linie (Regressionslinie) durch die Punkte zu ziehen. Und zwar so, dass der Fehler (Abstand zu den Punkten) in der Summe am geringsten ist. Wie wir im Bild unten sehen wurde beim **Underfitting** diese Aufgabe nicht gut genug erfüllt. Das mittlere Bild zeigt den **optimalen Fall**, wo der Fehler gering ist und das Modell vermutlich gute Vorhersagen macht. Beim **Overfitting** hingegen, sieht man, dass es einfach die Punkte \"auswendig\" gelernt hat. Der Fehler ist zwar bei genau diesen Daten fast Null. Neue, ungesehene Datenpunkte werden jedoch sehr wahrscheinlich nicht auf dieser Linie liegen und einen grösseren Fehler als im optimalen Fall aufweisen.\n",
    "\n",
    "![Underfitting_e_overfitting](../assets/02_Underfitting_overfitting.png)  \n",
    "<small>Quelle https://upload.wikimedia.org/wikipedia/commons/d/d2/Underfitting_e_overfitting.png (CC)</small>\n",
    "\n",
    "Over- und Underfitting lässt sich auch aus der **Lernkurve** erkennen. Diese zeichnet auf, wie sich der Fehler während des Trainings verändert. Und zwar einmal für die Trainingsdaten, sowie für die Validierungsdaten. Gut zu sehen ist, wie der Fehler am Anfang bei beiden rasch geringer wird. Bei den Trainingsdaten wird der Fehler mit jedem weiteren Durchlauf noch geringer. Mit den Validierungsdaten wird der Fehler aber irgendwann wieder grösser, es kommt zu Overfitting. Das Optimum würde hier also bei ca. 75 Durchlaufen liegen.\n",
    "\n",
    "![Learning-Curves](../assets/02_plot_loss.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter und Metriken\n",
    "\n",
    "Zum Schluss lernen wir noch einige wichtige Parameter sowie Metriken für das Training kennen. Mit den Parametern können wir den Trainingsablauf optimieren, das bedeutet ihn schneller und besser zu machen. Mit Metriken erhalten wir einen Wert für die Qualität unseres Modells.\n",
    "\n",
    "- **Learning Rate (LR):** Die Lernrate (englisch: Learning Rate) gibt an, wie \"schnell\" das neuronale Netzwerk lernt. Ist dieser Parameter klein, dann dauert das Training zu lange. Ist er zu gross, dann finden wir eventuell nie das Optimum. Bildlich gesprochen: Wie stark ändern wir nach jedem Durchlauf die Gewichte. Es gibt keinen allgemeinen Wert, sondern dieser ist je nach Modell und Aufgabe anders. In der Regel liegt dieser Wert in einem Bereich zwischen 0.001 und 0.1.\n",
    "\n",
    "- **Batch-Size**: Lernen, respektive das Justieren der Gewichte ist sehr aufwändig. In der Praxis lassen wir deshalb immer mehrere Datensätze durchlaufen und justieren diese einmalig zusammen. Das macht das Training effizient und daher schneller. Die Batch-Size gibt an, wie viele Trainingsdaten zusammen durchlaufen. Meistens werden 2er Potenzen (also 2, 4, 8 ...64) genommen, da das für Computer ideal ist.\n",
    "\n",
    "- **Epochen:** Dieser Wert gibt an, wie viele Trainingsdurchläufe wir machen. Das heisst, wie oft lassen wir die gesamten Trainingsdaten durchlaufen. Machen wir das zu wenig, dann ist unser Modell **underfitted**, machen wir es zu oft, kann es **overfitten** oder es passiert irgendwann nichts mehr. Der optimale Wert lässt sich aus der Lernkurve herauslesen und kann je nach Situation unterschiedlich sein.\n",
    "\n",
    "- **Metriken (Metric):** Die Metriken messen die Qualität unseres Modells. Zum Beispiel kann man mit der **Accuracy** (Genauigkeit) angeben, wie viel Prozent der Bilder richtig erkannt wurden [$ Accuracy = Richtige / (Richtige + Falsche)$]. Dieser Wert in Prozent ist somit aussagekräftiger, als der rohe Fehlerwert (englisch: Loss), welcher intern für das Lernen benützt wird."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
