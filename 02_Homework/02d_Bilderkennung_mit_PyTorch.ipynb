{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VkXQhHyuzg3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bilderkennung mit PyTorch Lightning\n",
    "\n",
    "In diesem Notebook trainieren wir unser erstes neuronales Netz. Wir folgen dabei dem ML-Ablauf, sammeln Erfahrungen mit Convolution Neuronal Netzwerken (siehe Theorieteil) und vertiefen unser Wissen mit Pytorch und Lightning.\n",
    "\n",
    "*Tipp:* F√ºr die Themen rund um PyTorch und Lightning wie zum Beispiel `DataSets`, `DataLoader` und `Trainer` kannst du dich am Notebook `AI_LinRegression` aus Woche 1 orientieren.\n",
    "\n",
    "Hier nochmals zur Erinnerung der Ablauf beim Machine Learning:\n",
    "\n",
    "1. Daten sammeln\n",
    "2. Daten aufbereiten\n",
    "3. Modell definieren & trainieren\n",
    "4. Modell validieren\n",
    "5. Modell optimieren\n",
    "6. Modell ben√ºtzen\n",
    "\n",
    "Wie ihr an den folgenden Kapiteln sieht, gehen wir genau so vor.\n",
    "\n",
    "*Tipp:* Klappe das Inhaltsverzeichnis auf, um dir einen √úberblick zu verschaffen.\n",
    "\n",
    "‚ö†Ô∏è **In diesem Notebook befinden sich Aufgaben. Ihr m√ºsst die gel√∂sten Aufgaben eurem Coach abgeben, damit sie bewertet werden.** ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als erstes importieren wir die Packages welche wir brauchen und pr√ºfen ob wir ein GPU zur verf√ºgung haben:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kxgJCfgVuzg4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "print(f'Is GPU (Cuda) available: {torch.cuda.is_available()}')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(torch.cuda.get_device_name(device=device))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsG5eboTuzg5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Daten sammeln\n",
    "\n",
    "In diesem Notebook werden wir diese nicht selbst sammeln, sondern Daten verwenden, die es schon gibt.\n",
    "\n",
    "Es gibt viele bekannten Datensets, welche kostenlos im Internet verf√ºgbar sind. Eins davon ist die [MNIST-Datenbank mit handgeschriebenen Ziffern](https://de.wikipedia.org/wiki/MNIST-Datenbank). Dieses umfasst 60'000 kleine Schwarz/Weiss Bilder mit Gr√∂sse 28x28 Pixel, welche handgeschriebene Ziffern von 0 bis 9 zeigen. Wir begn√ºgen uns mit einem Teil davon, erstmal 1'000, damit das Training schneller geht.\n",
    "\n",
    "Du findest diese Bilder auf GitLab am gleichen Ort wie dieses Notebook unter `02_Homework\\mnist_1k.zip`. Lade es herunter und entpacke das ZIP."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-m4ztExuzg5",
    "outputId": "2ca823dd-6610-4052-ffab-63cff2cf91be",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Pfad mit dem Ordner, wo die Bilder liegen. √Ñndere den Pfad, falls die Dateien bei dir an einem anderen Ort liegen.\n",
    "image_directory_path = Path('./mnist_1k')\n",
    "\n",
    "if not image_directory_path.exists():\n",
    "    print(f\"üõë Fehler: Der Pfad ./mnist_1k/ existiert nicht. Entpacke das .zip file.\")\n",
    "else:\n",
    "    print(f\"Alles gutüëç der Pfad {image_directory_path} wurde gefunden\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Funktion, um alle Bilder im Ordner zu finden und als Path Objekte zur√ºckzugeben\n",
    "def get_image_paths(path: Path) -> list:\n",
    "    return list(sorted(path.glob('**/*.png')))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Alle Bilder-Pfade laden\n",
    "image_paths = get_image_paths(image_directory_path)\n",
    "print(f\"Anzahl der Bilder: {len(image_paths)}\")\n",
    "assert len(image_paths) == 1_000, \"Es sollten 1_000 Bilder vorhanden sein\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlN8pzKPuzg6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nun schauen wir uns eines dieser Bilder an. Dazu ben√ºtzen wir die Libraries `PIL` und `matplotlib`, welche ihr aus den Python Aufgaben kennt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ein Bild anzeigen\n",
    "image_path = image_paths[0]\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Datei {image_path.name}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQeq32Dpuzg6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Daten aufbereiten\n",
    "\n",
    "Wir m√ºssen die Daten so aufbereiten, dass PyTorch diese \"versteht\" und mit diesen arbeiten kann.\n",
    "\n",
    "### Aufgabe 2.1\n",
    "\n",
    "Aus dem Dateinamen k√∂nnen wir erkennen, welche Ziffer das Bild zeigt: `mnist<Index>_<Ziffer>.png`.\n",
    "\n",
    "Erstelle also eine Funktion `get_label`, welche einen Dateipfad als `str` nimmt, die Ziffer aus dem Dateinamen extrahiert und als `int` zur√ºckgibt.\n",
    "\n",
    "Tipps:\n",
    "- Du kannst eine Ziffer als Sting mit der Funktion `int` in eine Zahl umwandeln. Beispiel `int(\"9\")`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Funktion, welche aus dem Dateipfad das Label extrahiert\n",
    "def get_label(path: str) -> int:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Funktion, welche aus dem Dateipfad das Label extrahiert\n",
    "def get_label(path) -> int:\n",
    "    return int(Path(path).stem[-1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TESTS der Funktion get_label\n",
    "\n",
    "test_path = \"02_Homework/mnist_1k/mnist0_2.png\"\n",
    "assert get_label(test_path) == 2, \"Fehler bei der Extraktion des Labels (2)\"\n",
    "test_path = \"02_Homework/mnist_1k/mnist999_0.png\"\n",
    "assert get_label(test_path) == 0, \"Fehler bei der Extraktion des Labels (0)\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Target ist aber keine Nummer wie bei der Regression, sondern es gibt 10 Klassen, da wir 10 Ziffern (0-9) haben. Daher m√ºssen wir eine Liste machen, wobei alle Werte auf 0 sind, ausser der Index der Ziffer ist 1. Diese Vorgehen nennt man auch [\"one-hot encoding\"](https://de.wikipedia.org/wiki/1-aus-n-Code)\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "- Ziffer 0 = [1,0,0,0,0,0,0,0,0,0]\n",
    "- Ziffer 1 = [0,1,0,0,0,0,0,0,0,0]\n",
    "- Ziffer 9 = [0,0,0,0,0,0,0,0,0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# On-hot encoding des Labels\n",
    "def label_encoding(label: int) -> torch.Tensor:\n",
    "    encoding = [0] * 10\n",
    "    encoding[label] = 1\n",
    "    return torch.tensor(encoding, dtype=torch.float32)\n",
    "\n",
    "# Wenn wir schon dabei sind, das Selbe in die andere Richtung\n",
    "# Wir geben das Label mit dem h√∂chsten Wert zur√ºck\n",
    "def label_decoding(label: torch.Tensor) -> int:\n",
    "    return label.argmax().item()\n",
    "\n",
    "# TESTS label_encoding\n",
    "assert label_encoding(0).tolist() == [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"Fehler bei der Kodierung des Labels (0)\"\n",
    "assert label_encoding(4).tolist() == [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], \"Fehler bei der Kodierung des Labels (9)\"\n",
    "assert label_decoding(torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])) == 0, \"Fehler bei der Dekodierung des Labels (0)\"\n",
    "assert label_decoding(torch.tensor([0, 0, 0, 0, 0.8, 0, 0, 0, 0, 0])) == 4, \"Fehler bei der Dekodierung des Labels (9)\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.2\n",
    "\n",
    "Nun m√ºssen wir noch einen `DataLoader` erstellen, welcher die Bilder einliest, und in ein Format bringen, welches das neuronale Netzwerk als Eingangsignal verwenden kann (Scaling). Letzteres bedeutet, die Pixelwerte, welche zwischen 0-255 liegen, auf einen Wert zwischen 0.0 und 1.0 bringen. Nat√ºrlich muss unser Dataset auch das Label zur√ºckgeben.\n",
    "\n",
    "Tipps:\n",
    "- Orientiere dich am Dataloader im Notebook LinRegression von letzter Woche.\n",
    "- Als Parameter in der `__init__` Methode wird eine Liste von Bildpfaden √ºbergeben (das was aus `get_image_paths` herauskommt)\n",
    "- Wichtig: Die Bilder sollen erst geladen werden, wenn sie ben√∂tigt werden (`__getitem__`). Ansonsten ben√ºtzten wir zu viel Speicher\n",
    "- In der `__getitem__` Methode wird folgendes gemacht:\n",
    "  - Das Bild soll eingelesen werden (mit `Image.open`)\n",
    "  - Das Bild soll in einen `float32` Tensor gewandelt werden (ben√ºtzte dazu `pil_to_tensor`)\n",
    "  - Danach muss der Tensor skaliert werden, sodass dessen Werte zwischen 0.0 und 1.0 liegen (teile dazu den Tensor einfach durch 255.0)\n",
    "  - Das Label muss aus dem Bildpfad gelesen werden (`get_label`) und codiert werden (`label_encoding`)\n",
    "  - Gebe anschliessend den Bild-Tensor und das codierte Label zur√ºck (`tuple(tensor, label_encoded)`)\n",
    "  - Schaue, dass du die alle anschliessenden Tests erf√ºllst\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "# Erstelle ein Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    # Initialisierung des Datasets mit den Bildpfaden\n",
    "    def __init__(self, image_paths):\n",
    "        pass\n",
    "\n",
    "    # Gib die L√§nge des Datasets zur√ºck\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    # Gebe das den Bild-Tensor und das encodierte Label f√ºr den Index idx zur√ºck\n",
    "    def __getitem__(self, idx):\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "# Dataset, welches die Bilder und Labels enth√§lt\n",
    "# SOLUTION\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    # Gib die L√§nge des Datasets zur√ºck\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    # Lade das Bild und das Label-Encoding. Gebe ein Tuple (image, label) zur√ºck\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        \n",
    "        image = Image.open(path)\n",
    "        image_tensor = pil_to_tensor(image)\n",
    "        image_tensor = image_tensor / 255.0 # Skaling\n",
    "        \n",
    "        label = get_label(path)\n",
    "        label_encoded = label_encoding(label)\n",
    "        \n",
    "        return image_tensor, label_encoded"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TESTS ImageDataset\n",
    "\n",
    "# Arrange (10 Bilder erstellen)\n",
    "import tempfile\n",
    "p = Path(tempfile.gettempdir()) / \"test2-2\"; p.mkdir(exist_ok=True)\n",
    "images = [Image.new('L', (28, 28), int(25.5 * i)).save(p / f\"mnist9{i}9_{i}.png\") for i in range(10)]\n",
    "test_image_paths = get_image_paths(p)\n",
    "\n",
    "# Act\n",
    "try:\n",
    "    ImageDataset(test_image_paths)\n",
    "except Exception as e:\n",
    "    assert False, f\"Es gab einen Fehler beim Erstellen des Datasets: {e}\"\n",
    "test_dataset = ImageDataset(test_image_paths)\n",
    "assert len(test_dataset) == 10, \"Die L√§nge des Datasets sollte 10 sein\"\n",
    "assert type(test_dataset[0]) is tuple, \"Es sollte ein Tuple zur√ºckgegeben werden\"\n",
    "assert len(test_dataset[0]) == 2, \"Das zur√ºckgegebene Tuple sollte 2 Elemente haben\"\n",
    "assert type(test_dataset[0][0]) is torch.Tensor, \"Das erste Element des Tuples sollte ein Tensor sein\"\n",
    "assert test_dataset[0][0].shape == (1, 28, 28), \"Der Image Tensor sollte die Shape (1, 28, 28) haben\"\n",
    "assert test_dataset[0][0].max() <= 1.0, \"Die Werte des Image Tensors sollten zwischen 0 und 1 liegen\"\n",
    "assert test_dataset[0][0].min() >= 0.0, \"Die Werte des Image Tensors sollten zwischen 0 und 1 liegen\"\n",
    "assert test_dataset[0][0].dtype == torch.float32, \"Der Image Tensor sollte den Datentyp float32 haben\"\n",
    "assert type(test_dataset[0][1]) is torch.Tensor, \"Das zweite Element des Tuples sollte ein Tensor sein\"\n",
    "assert test_dataset[0][1].shape == (10,), \"Der Label Tensor sollte die Shape (10,) haben\"\n",
    "\n",
    "# Cleanup\n",
    "import shutil; shutil.rmtree(p)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun m√ºssen wir, wie wir gelernt haben, ein Trainings- und Validierungsset erstellen (split) und danach die `Datenloaders`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Wir erstellen unser Dataset\n",
    "dataset = ImageDataset(image_paths)\n",
    "\n",
    "# Wir werden 80% der Daten f√ºr das Training verwenden und 20% f√ºr das Validieren\n",
    "train_dataset, val_dataset = random_split(dataset=dataset, lengths=[0.8, 0.2], generator=torch.Generator().manual_seed(3))\n",
    "# (den generator ben√∂tigen wir nur, damit die Zuf√§lligkeit reproduzierbar ist. In der Praxis lassen wir das weg)\n",
    "\n",
    "# √úberpr√ºfen wir mal die Gr√∂sse dieser Sets\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "assert (len(train_dataset), len(val_dataset)) == (800, 200)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Erstellen der DataLoaders\n",
    "BATCH_SIZE = 128\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Ein Batch aus dem DataLoader laden und dessen Shape anzeigen\n",
    "images, labels = next(iter(training_loader))\n",
    "print(f\"Input shape: {images.shape}\")\n",
    "print(f\"Output shape {labels.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlIaDwfSuzg7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Aufgabe (Selbststudium)\n",
    "\n",
    "<details>\n",
    "  <summary>√úberlege dir, was die einzelnen Zahlen Input Shape <code>[[128, 1, 28, 28]]</code> bedeuten? Klicke anschliessend auf den Pfeil, um die L√∂sung zu sehen.</summary>\n",
    "    <br>Es gibt genau 4 Dimensionen in genau dieser Reihenfolge:\n",
    "    <ul>\n",
    "      <li>128: Die Batch-Size (also 128 Bilder pro Batch)</li>\n",
    "      <li>1: Anzahl Farbkan√§le. Da wir schwarz/weiss Bilder haben nur einer</li>\n",
    "      <li>28: H√∂he der Bilder in Pixel</li>\n",
    "      <li>28: Breite der Bilder in Pixel</li>\n",
    "    </ul> \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN3e7I8wuzg7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modell definieren & trainieren\n",
    "\n",
    "Wir definieren nun unser Model, unser Trainer und sind schon bereit f√ºr unser Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvqrwOEsuzg7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modell definieren\n",
    "\n",
    "Wir versuchen es mal mit einem Dense Neuronal Netzwerk, dass heist vorerst mal ohne Convolution Layers.\n",
    "\n",
    "Wie ein `LightningModule` aussieht und was die einzelnen Teile machen, solltest du aus dem `LinRegression` Notebook der letzten Woche wissen (und sonst schaue dort nach). Es werden nur noch neuen Sachen beschrieben! "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06G_bAMKoENO",
    "outputId": "6b4779c8-b9c7-427e-ecef-5c82daa5f39b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from lightning import LightningModule, Trainer\n",
    "\n",
    "\n",
    "class DenseModel(LightningModule):\n",
    "    # NEU Die Lernrate geben wir als Parameter mit, damit wir sie sp√§ter einfach anpassen k√∂nnen\n",
    "    def __init__(self, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.logged_metrics = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "        }\n",
    "        \n",
    "        # Der erste Layer hat als Input alle Pixel (28*28 = 784) und als Output 16 Neuronen\n",
    "        self.linear1 = torch.nn.Linear(784, 16)\n",
    "        # Wichtig: Wir ben√∂tigen eine Aktivierungsfunktion, um komplexere Zusammenh√§nge lernen zu k√∂nnen\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        \n",
    "        # Zum Schluss ben√∂tigen einen Layer wir 10 Neuronen als Output, da wir 10 Labels haben (Ziffern 0-9)\n",
    "        # Als Input hat er die Anzahl Neuronen das Layers davor\n",
    "        self.linear_out = torch.nn.Linear(16, 10)\n",
    "        \n",
    "        # Bei Klassifizierung verwenden wir als letztes die Softmax-Funktion, um f√ºr jeden Output eine Wahrscheinlichkeit zwischen 0..1 zu erhalten\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Beim linearen Layer m√ºssen wird das Bild, welcher zwei Dimension hat (28,28) in eine Dimension (784) umwandeln\n",
    "        x = x.view(-1, 784)\n",
    "        \n",
    "        # Hier gehen die Daten durch die Schichten\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        y_pred = self(x)\n",
    "        # Wichtig: F√ºr Classification verwenden wir die CrossEntropyLoss Funktion\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred, y)\n",
    "        self.logged_metrics[\"train_loss\"].append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_pred = self(x)\n",
    "        # Wichtig: F√ºr Classification verwenden wir die CrossEntropyLoss Funktion\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred, y)\n",
    "        self.logged_metrics[\"val_loss\"].append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "w5nblp6wuzg7",
    "outputId": "92f83c74-cc6c-4fd9-e9f5-5e7e2ff74a89",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Wir k√∂nnen uns ansehen, wie die Architektur des Modells aussieht.\n",
    "# Hier sieht man die einzelnen Schichten, welche Ausgangssignale (Output Shape) sie erzeugen, sowie die Anzahl k√ºnstlicher Neuronen (Param #), welche sie enthalten.\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelSummary\n",
    "ModelSummary().on_fit_start(Trainer(), DenseModel())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuFmKYhPuzg8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Schaue die Architektur an und beantworte folgende Frage:\n",
    "\n",
    "<details>\n",
    "  <summary>Wie viele Gewichte m√ºssen wir trainieren?</summary>\n",
    "  \n",
    "  `Total trainable params: 12.7k`  \n",
    "  Also 12'700, eine ganze Menge... zum Gl√ºck m√ºssen wir das nicht von Hand machen üòâ\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_OvH3Okuzg8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Trainieren\n",
    "\n",
    "Nun k√∂nnen wir unser Netzwerk trainieren. Wir geben dazu noch die Anzahl **Epochen** (komplette Durchl√§ufe) an.\n",
    "\n",
    "Das Training dauert eine Weile... "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "qB6xuoXquzg8",
    "outputId": "03593bab-1606-4bf1-d601-6233805bf836",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Anzahl Epochen definieren\n",
    "EPOCHS = 100\n",
    "\n",
    "# Trainer initialisieren. Diesmal ben√ºtzten wir die GPU (falls keine verf√ºgbar ist, kannst du auch 'cpu' verwenden)\n",
    "trainer = Trainer(max_epochs=EPOCHS, accelerator='gpu')\n",
    "\n",
    "# Modell initialisieren\n",
    "LEARNING_RATE = 0.001\n",
    "model = DenseModel(lr=LEARNING_RATE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "# ‚¨Ü Die Zeile \"%%time\" oben, sorgt daf√ºr, dass unten angezeigt wird, wie lange es gedauert hat, diese Notebook Zelle auszuf√ºhren.\n",
    "# Wir k√∂nnen somit sehen, wie lange das Training gedauert hat. Um die Resultate zu vergleichen, ben√ºtzt du am besten 'CPU times' (und nicht 'Wall time').\n",
    "# Wir definieren die Lernrate und die Anzahl Epochen f√ºr unser Training.\n",
    "\n",
    "# Das Training starten. Dieses dauert eine Weile...\n",
    "trainer.fit(model, training_loader, validation_loader)\n",
    "\n",
    "# Unterhalb sehen wir den Vortschritt:"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-Sr2m7Xuzg8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training anzeigen\n",
    "\n",
    "Wir k√∂nnen uns den Verlauf des Trainings anzeigen lassen. Die Grafik unten zeigt uns, wie sich der Fehler (`loss`) w√§hrend des Trainings entwickelt hat. Und zwar einmal beim Trainings-Set wie auch beim Validierungs-Set. Daraus k√∂nnen wir ablesen, ob es zu einem **Over/Underfitting** gekommen ist."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Nun k√∂nnen wir uns die Trainings- und Validierungsfehler anschauen\n",
    "train_loss = model.logged_metrics[\"train_loss\"]\n",
    "val_loss = model.logged_metrics[\"val_loss\"]\n",
    "plt.plot(train_loss, label=\"train_loss\")\n",
    "plt.plot(\n",
    "    [int(i * (len(train_loss) / len(val_loss))) for i in range(len(val_loss))],\n",
    "    val_loss,\n",
    "    label=\"val_loss\",\n",
    ")\n",
    "# Die X-Achse mit Epochs beschriften. Jedoch max 10 Beschriftungen\n",
    "plt.xticks(\n",
    "    ticks=[i * (len(train_loss) // 10) for i in range(10)],\n",
    "    labels=[f\"{i*(EPOCHS//10)}\" for i in range(10)],\n",
    ");\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Fehler)\")\n",
    "plt.legend()\n",
    "\n",
    "# Logarithmische Skala f√ºr die Y-Achse, da die Werte sehr gross sind\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "# Wir sehen, wie der Fehler immer geringer wird. Am Anfang schneller, wird die Kurve sehr flach\n",
    "# Tipp: Schalte oben die logarithmische Skala ein, um die Kurve besser zu sehen!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√úberpr√ºfe die Lernkurve, kommt es zu Overfitting? Wenn Ja, reduziere die Anzahl Epochen"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Der Fehler am Ende des Trainings war:\n",
    "print(f\"Trainingsfehler: {train_loss[-1]:.3f}\")\n",
    "print(f\"Validierungsfehler: {val_loss[-1]:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eine Vorhersage machen\n",
    "\n",
    "Damit wir nachher einfacher Vorhersagen machen k√∂nnen, bauen wir uns eine `predict` Funktion mit dem Model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def predict(img_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(img_tensor.unsqueeze(0))\n",
    "    # R√ºckgabe ist das das Label, sowie die Wahrscheinlichkeiten f√ºr jedes Label\n",
    "    return label_decoding(y_pred), y_pred[0].tolist()\n",
    "\n",
    "# Testen wir unsere Funktion\n",
    "image_tensor, _ = dataset[0]\n",
    "pred_label, predict_props = predict(image_tensor)\n",
    "print(f\"Predicted label: {pred_label}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWtzfUd7uzg8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Validieren\n",
    "\n",
    "Wir schauen nun, wie gut unser Modell performt, also wie gut unser Modell mit noch nicht gesehenen Daten ist\n",
    "\n",
    "Als erstes machen wir eine einzelne Vorhersage mit einem zuf√§lligen Bild (du kannst die untere Zelle mehrmals ausf√ºhren und bekommst immer ein anderes Bild).\n",
    "\n",
    "Wir betrachten insbesondere den Output des Modells. Schaue, dass du genau verstehst welche Werte aus dem Modell herauskommen und was diese bedeuten!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# Wir laden ein zuf√§lliges Bild/Label Paar\n",
    "image_tensor, label_encoded = val_dataset[random.randint(0, len(val_dataset))]\n",
    "\n",
    "# Wir plotten das Bild\n",
    "image = to_pil_image(image_tensor)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {label_decoding(label_encoded)}\")\n",
    "\n",
    "# Wir geben das Bild als Input in unser Modell\n",
    "pred_label, pred_props = predict(image_tensor)\n",
    "\n",
    "# Als ersten schauen wir uns den unformatierten Output des Modells an\n",
    "print(f\"Vorhersage (Model output): {[round(p, 2) for p in pred_props]}\")\n",
    "\n",
    "# Wir dekodieren die Vorhersage\n",
    "print(f\"H√∂chster Wert im Output an Index {pred_label} (somit ist die Vorhersage diese Ziffer)\")\n",
    "\n",
    "# Wir k√∂nnen uns auch anschauen, wie sicher sich das Modell ist (wie hoch die Wahrscheinlichkeit ist)\n",
    "prediction_probability = pred_props[pred_label]\n",
    "print(f\"Das Modell ist sich dabei zu {prediction_probability:.0%} sicher\")\n",
    "\n",
    "# Wir pr√ºfen, ob die Vorhersage korrekt ist\n",
    "true_label = label_decoding(label_encoded)\n",
    "correct = pred_label == true_label\n",
    "print(f\"Die Vorhersage ist {'korrekt üëçÔ∏è' if correct else 'falsch üòø'}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe (Selbststudium)\n",
    "\n",
    "- F√ºhre die Zelle oben mehrmals aus, bis du einen Fall findest, wo das Modell falsch liegt.\n",
    "\n",
    "- Siehst du einen Grund daf√ºr? H√§ttest du die Ziffer eindeutig erkannt?\n",
    "\n",
    "- Verstehst du, was der Output des Models ist und wie es mit dem encoding/decoding (Stichwort: One-hot encoding von weiter oben) zusammenh√§ngt?\n",
    "\n",
    "Beantworte folgende Fragen:\n",
    "\n",
    "<details>\n",
    "  <summary>1. Warum ist der Output eine Liste und hat sie die L√§nge 10? Klicke auf den Pfeil, um die L√∂sung zu sehen.</summary>\n",
    "    <br> Die Liste hat die L√§nge 10, da es genau 10 Output-Neuronen gibt - f√ºr jede Ziffer eins\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>2. Was bedeuten die einzelnen Zahlen im Output?</summary>\n",
    "    <br> Jeder Wert widerspiegelt die Wahrscheinlichkeit f√ºr diese Ziffer. Zusammen ergeben alle Zahlen immer 1.0 (daf√ºr sorgt die SoftMax Funktion am Schluss unseres Netzwerkes).\n",
    "    <br> Also wenn eine Stelle 1.0 ist und alle anderen 0.0, dann ist sich das Modell sehr sicher bei der Ziffer.\n",
    "    <br> Und wenn ein Wert 0.51 ist und ein anderer 0.49, dann kann sich das Modell nicht zwischen diesen zwei Ziffer entscheiden.\n",
    "    <br> Und wenn alle Werte 0.1 (1/10) haben, dann hat das Model keine Ahnung.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der n√§chsten Zelle machen wir mehrere Vorhersagen und schauen uns ebenfalls das Bild dazu an.  \n",
    "(Du kannst die Zelle ebenfalls mehrmals ausf√ºhren um neue Bilder zu erhalten.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "SJDXcA6Ouzg8",
    "outputId": "81f027ac-7085-4a52-9932-e1528080f5a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Ein paar (zuf√§llige) Vorhersagen aus dem Validationset machen.\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n = 5\n",
    "    fig, axs = plt.subplots(1, n, figsize=(20, 4))\n",
    "    axs = axs.flatten()\n",
    "    for i, ax in enumerate(axs):\n",
    "        image, label_encoded = val_dataset[random.randint(0, len(val_dataset))]\n",
    "        label_decoded = label_decoding(label_encoded)\n",
    "        prediction = model(image.unsqueeze(0))\n",
    "        prediction_decoded = label_decoding(prediction)\n",
    "        is_correct = 'RICHTIG' if label_decoded==prediction_decoded else 'FALSCH'\n",
    "        ax.imshow(image.squeeze(), cmap='gray')\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(f\"{is_correct}: {label_decoded} vorhergesagt als {prediction_decoded}\\n(Warscheinlichkeit von {prediction.max().item():.1%})\")\n",
    "        ax.title.set_color('green' if label_decoded==prediction_decoded else 'red')\n",
    "        # print(f\"{'RICHTIG' if label_decoded==prediction_decoded else 'FALSCH'}\\t Ziffer {label_decoded} vorhergesagt als Ziffer {prediction_decoded} mit einer Warscheinlichkeit von {prediction.max().item():.1%}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metriken\n",
    "\n",
    "Als n√§chste wollen wir einen Wert, um anzugeben wie gut unser Modell ist. Daf√ºr eignet sich wie in der Theorie beschrieben die Accuracy (Genauigkeit). Diese gibt an, wie oft in Prozent das Modell richtig lag."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Wir lassen und das gesamte Validation-Dataset durch das Modell laufen und die Vorhersagen machen\n",
    "pred_labels = []\n",
    "true_labels = []\n",
    "correct = 0\n",
    "for img_tensor, label_encoded in val_dataset:\n",
    "    true_label = label_decoding(label_encoded)\n",
    "    true_labels.append(true_label)\n",
    "    pred_label = predict(img_tensor)[0]\n",
    "    pred_labels.append(pred_label)\n",
    "    if true_label == pred_label:\n",
    "        correct += 1\n",
    "\n",
    "# Wir berechnen die Genauigkeit\n",
    "accuracy = correct / len(val_dataset)\n",
    "\n",
    "print(f\"Genauigkeit: {accuracy:.2%}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit sollte bei ca. 50% liegen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Aber wo lag das Model richtig und wo hatte es M√ºhe?\n",
    "\n",
    "Ein weitere wichtiges Hilfsmittel ist die sogenannte Confusion Matrix.\n",
    "Diese zeigt den unterschied zwischen Vorhersage und echtem Label an.\n",
    "\n",
    "Damit du verstehst, wie diese Funktioniert und wie sie zu lesen ist, schaue dir [diesen Artikel](https://databasecamp.de/ki/konfusionsmatrix) an (min. bis Kapitel 3.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "# Wir erstellen eine Confusion Matrix Funktion\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "# Wir berechnen die Werte der Confusion Matrix\n",
    "confusion_matrix = confmat(\n",
    "    torch.tensor(pred_labels),\n",
    "    torch.tensor(true_labels),\n",
    ")\n",
    "\n",
    "# Zum Schluss plotten wir die Confusion Matrix\n",
    "confmat.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Diagonale zeigt uns, wie oft wir richtig lagen (True == Predict)\n",
    "\n",
    "An den anderen Felder, sehen wir, wo es h√§ufig zu Verwechslungen kommt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weitere Aufgaben\n",
    "\n",
    "Bei den letzten zwei Aufgaben entwickelst du das neuronale Netz weiter, um die Genauigkeit zu erh√∂hen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.3\n",
    "\n",
    "**Wichtig:** Mache eine Kopie dieses Notebooks um diese Aufgabe zu l√∂sen.\n",
    "\n",
    "Erweitere die `DenseNet` Klasse um einen lineare Layer und erh√∂he die Anz. Neuronen im ersten Layer.\n",
    "Die `__init__` Funktion sollte folgendes enthalten:\n",
    "\n",
    "```python\n",
    "    # Der erste Layer mit 128 anstatt 32 Neuronen\n",
    "    self.linear1 = torch.nn.Linear(784, 128)\n",
    "    self.relu1 = torch.nn.ReLU()\n",
    "\n",
    "    # Ein neuer \"hidden\" Layer mit 64 Neuronen\n",
    "    self.linear2 = torch.nn.Linear(128, 64)\n",
    "    self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "    # Die Input-Size beim letzten Layer muss angepasst werden (== Output-Size des vorherigen Layers)\n",
    "    self.linear_out = torch.nn.Linear(64, 10)\n",
    "    self.softmax = torch.nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "**Frage:** Was musst du in der `forward` Funktion √§ndern, damit die Layer auch ben√ºtzt werden?\n",
    "\n",
    "**Frage:** Welche Genauigkeit erh√§ltst du mit dem neuen Netzwerk? Und siehst du auch eine Verbesserung in der Confusion Matrix?\n",
    "\n",
    "**Frage:** Wie viele Parameter m√ºssen trainiert werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.3\n",
    "\n",
    "**Wichtig:** Mache eine Kopie dieses Notebooks um diese Aufgabe zu l√∂sen.\n",
    "\n",
    "Baue nun die `DenseNet` Klasse zu einen Convolution Neuronal Network um, in dem du `Convoltion2D` Layer hinzuf√ºgst.\n",
    "\n",
    "Die `__init__` Funktion sollte folgendes enthalten:\n",
    "\n",
    "```python\n",
    "\n",
    "        # Einen 2D Convolution-Layer mit 32 Neuronen und einen 3x3 Kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Es folgt ein Max-Pooling, um die Datengr√∂sse zu halbieren (von 28x28 auf 14x14)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Danach ein Dense Layer mit 64 Neuronen\n",
    "        self.linear1 = torch.nn.Linear(14*14*32, 64)\n",
    "        \n",
    "        # Und unser Output-Layer\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.linear_out = torch.nn.Linear(64, 10)\n",
    "```\n",
    "\n",
    "Die `forward` Funktion sollte so aussehen:\n",
    "\n",
    "```python\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Wichtig: Beim Eingang kein gl√§tten mehr n√∂tig, da wir Convolutional Layer verwenden, welcher 2-dimensional eBilder aufnimmt\n",
    "        # x = x.view(-1, 784)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Aber nach dem Convolutional Layer m√ºssen wir die Dimensionen wieder gl√§tten\n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        # Nach der Convolution folgt ein lineares Netzwerk\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # Und zum Schluss die Ausgabe\n",
    "        x = self.linear_out(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "**Frage:** Welche Genauigkeit erh√§ltst du mit dem neuen Netzwerk? Und siehst du auch eine Verbesserung in der Confusion Matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe (freiwillig)\n",
    "\n",
    "- Ver√§ndere die Hyperparamter Lernrate, Batch-Size und Epochs. Kannst du eine bessere Genauigkeit erreichen oder das Training beschleunigen (gleiche Genauigkeit, aber in k√ºrzere Zeit)?\n",
    "\n",
    "- Kannst du die Genauigkeit mit mehr Daten erh√∂hen? Nehme dazu die Daten aus `mnist_10k.zip` (also 10x mehr Daten). Vermutlich musst du die Anzahl Epochen erh√∂hen, da man mit mehr Daten auch mehr lernen muss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
