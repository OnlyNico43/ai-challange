{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netzwerke f√ºr Bilderkennung\n",
    "Wie wir schon gelernt haben, brauchen wir f√ºr Bilderkennung ein Netzwerk, das mit sehr vielen Eingangsdaten arbeiten kann (jeder Bildpunkt in jeder der drei Grundfarben ergibt ein Signal). Dies f√ºhrt zu sehr grossen Netzwerken mit Tausenden von Neuronen. Mit einigen \"Tricks\" k√∂nnen wir sowohl die Anzahl Neuronen reduzieren, als auch dem Netzwerk helfen, andere Problem bei der Bilderkennung anzugehen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neuronal Network (CNN)\n",
    "\n",
    "### Einleitung / Funktionsweise\n",
    "\n",
    "Oft wird bei der Bilderkennung ein **Convolutional Neuronal Network (CNN)** eingesetzt. Dieses teilt das Eingangsbild in Bereiche auf und geht diese der Reihe nach durch. Mit verschiedenen, selbst gelernten **Filtern** erkennt es nun Formen (Linien, Formen, √úberg√§nge, Fl√§chen etc.) oder andere Eigenschaften (englisch: Features) auf den Teilbildern. Die nachfolgenden Schichten verfeinern dieses Vorgehen, sodass daraus immer h√∂here Features mit spezifischeren Informationen werden. Diese werden zum Schluss in ein herk√∂mmliches (voll verbundenes) neuronales Netzwerk gegeben, um das Resultat auszuwerten.\n",
    "\n",
    "Man kann sich das stark vereinfacht so vorstellen:\n",
    "1. Erste Schicht erkennt einfache Formen auf den Bildern. Wie Halbkreise, Linien, helle oder dunkle Bereiche etc.\n",
    "2. Die n√§chsten Schichten machen aus diesen einfachen Formen komplexere Features. Zum Beispiel ergeben mehrere Linien zusammen einen grossen Kreis. Am Schluss gibt es also ein Neuron, welche ein starkes Signal ausgibt, wenn ein grosser Kreis im Bild erkannt wurde. Oder zwei kleinere Kreise nebeneinander k√∂nnten als Augen-Feature erkennt werden.\n",
    "3. Das herk√∂mmliche neuronale Netzwerk am Ende bekommt dann diese h√∂heren Features anstatt lediglich Bildpunkte. So kann das Netzwerk bessere Aussagen machen. Beispiel: \"Zwei kleinere Kreise nebeneinander und ein gegen oben ge√∂ffneter Halbkreis\" = Smiley üòÄ\n",
    "\n",
    "![Convolutional_Neural_Network](https://upload.wikimedia.org/wikipedia/commons/6/6b/3_filters_in_a_Convolutional_Neural_Network.gif)  \n",
    "<small>Quelle https://commons.wikimedia.org/wiki/File:3_filters_in_a_Convolutional_Neural_Network.gif (CC)</small>\n",
    "\n",
    "Diese Informationen sollten uns als groben Einstieg gen√ºgen. Falls du dich weiter in das Thema vertiefen willst, dann schaue im Internet nach. Zum Beispiel:\n",
    "- Youtube-Video (englisch, 6min): [What are Convolutional Neural Networks (CNNs)?](https://youtu.be/QzY57FaENXg)\n",
    "- Artikel: [Convolutional Neural Network (CNN): Alles, was Du wissen solltest](https://datascientest.com/de/convolutional-neural-network-2)\n",
    "\n",
    "Du kannst dir auch nochmals die entsprechenden PowerPoint-Folien des Kick-Off-Days ansehen:\n",
    "- https://drive.switch.ch/index.php/s/4p866m51bwDdeq6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Architekturen\n",
    "\n",
    "Es gibt verschiedene Architekturen von CNN's, welche sich in der Art und Anzahl der Layer unterscheiden. Zum Beispiel:\n",
    "\n",
    "  - alexnet\n",
    "  - squeezenet1_1\n",
    "  - resnet18 / resnet34 / resnet50\n",
    "  - densenet121 / densenet161\n",
    "  - resnext50_32x4d\n",
    "\n",
    "(Du kannst dich [hier](https://pytorch.org/vision/stable/models.html#classification) √ºber die verf√ºgbaren Architekturen informieren.)\n",
    "\n",
    "Und nat√ºrlich kann man seine eigene Architektur definieren! So wie wir das im Trainings-Notebook von dieser Woche machen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arten von Layern\n",
    "\n",
    "Wenn du dir die Architekturen ansiehst, wirst du verschiedene Arten von Layern finden. Wir beschreiben hier kurz wie diese heissen und was diese machen:\n",
    "\n",
    "- `torch.nn.Linear(...)`: Dies ist ein Layer eines voll verbundenen (dense) neuronalen Netzes, wie wir es in der Theorie dieser Woche kennengelernt haben.\n",
    "- `torch.nn.Conv2d(...)`: Ein normaler Convolution-Layer. Und zwar f√ºr 2D-Daten (also Bilder mit H√∂he x Breite)\n",
    "- `torch.nn.MaxPool2d(...)`: Beim Pooling werden Pixelwerte benachbarter Pixel zusammengerechnet und so die Bildgr√∂sse verringert. Wir oft im Zusammenhang mit Convolution-Layer ben√ºtzt.\n",
    "- `torch.nn.Dropout(...)`: Diese Layer deaktivieren w√§hrend des Trainings zuf√§llige Neuronen. So wird das Resultat stabiler und die Gefahr von Overfitting verringert.\n",
    "- `torch.nn.Flatten(...)`: Dieser Layer formt mehrdimensionalen Ausgabewerte zu einer eindimensionalen (flachen) Liste um. Das macht man am Ende der Convolution-Layer, bevor das voll verbundene neuronale Netz folgt. \n",
    "- `torch.nn.BatchNorm1d(...)`: Bei der Normalisierung wird geschaut, dass alle Pixelwerte in einem √§hnlichen Bereich liegen (meistens zwischen 0.0 und 1.0). So verhindert man zu kleine oder zu grosse Zahlen, die beim Lernen st√∂ren k√∂nnten. Man kann ganz vereinfacht sagen, dass darauf geachtet wird, dass alle Bilder in etwa gleich hell sind.\n",
    "- `torch.nn.ReLU(...)`/`torch.nn.Sigmoid()`: Hierbei handelt es sich um zwei Arten von **Aktivierungsfunktionen**, wie in der Theorie vorgestellt. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
